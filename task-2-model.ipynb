{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# 2D Design Project",
   "metadata": {
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 8,
    "execution_start": 1635039167604,
    "source_hash": "ac9ae32f",
    "tags": [],
    "cell_id": "00000-024bd373-8def-4858-aaa0-a66791fd7534",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "<b>Problem Statement</b>: We wish to predict Singapore's GDP growth amidst COVID-19 based on various factors. By comparing the predicted growth rate with the actual growth rate, we can determine the effectiveness of Singapore's coping strategies against COVID-19.\n\nFactors/Variables to consider (from most to least important):\n- Time/date (time series data)\n- Vaccination rate\n- Daily active cases\n- Hospitalised\n- Recovered\n- Government grants/funding\n- Phases (circuit breaker, phase 1 etc.)\n\nPredict : \n- Growth rate of GDP",
   "metadata": {
    "tags": [],
    "cell_id": "00001-c0a0cba4-6dba-49bd-b568-aa5a20b1c2f3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Data Pre Processing",
   "metadata": {
    "tags": [],
    "cell_id": "00002-10466a07-a69c-43ef-af9b-7956d83a0ac7",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np \n\ndf = pd.read_csv('./output/processed_data.csv')",
   "metadata": {
    "tags": [],
    "cell_id": "00003-0f4f42d1-6d53-40b9-8880-3e068bc14aed",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fb2c4a30",
    "execution_start": 1636449726528,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "df.head()",
   "metadata": {
    "tags": [],
    "cell_id": "00004-e2e04e24-7c2a-462f-a263-02cfe3145e17",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c085b6ba",
    "execution_start": 1636449732579,
    "execution_millis": 30,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 5,
       "column_count": 8,
       "columns": [
        {
         "name": "Date",
         "dtype": "int64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "738004",
          "max": "738008",
          "histogram": [
           {
            "bin_start": 738004,
            "bin_end": 738004.4,
            "count": 1
           },
           {
            "bin_start": 738004.4,
            "bin_end": 738004.8,
            "count": 0
           },
           {
            "bin_start": 738004.8,
            "bin_end": 738005.2,
            "count": 1
           },
           {
            "bin_start": 738005.2,
            "bin_end": 738005.6,
            "count": 0
           },
           {
            "bin_start": 738005.6,
            "bin_end": 738006,
            "count": 0
           },
           {
            "bin_start": 738006,
            "bin_end": 738006.4,
            "count": 1
           },
           {
            "bin_start": 738006.4,
            "bin_end": 738006.8,
            "count": 0
           },
           {
            "bin_start": 738006.8,
            "bin_end": 738007.2,
            "count": 1
           },
           {
            "bin_start": 738007.2,
            "bin_end": 738007.6,
            "count": 0
           },
           {
            "bin_start": 738007.6,
            "bin_end": 738008,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "Still Hospitalised",
         "dtype": "int64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "516",
          "max": "572",
          "histogram": [
           {
            "bin_start": 516,
            "bin_end": 521.6,
            "count": 1
           },
           {
            "bin_start": 521.6,
            "bin_end": 527.2,
            "count": 1
           },
           {
            "bin_start": 527.2,
            "bin_end": 532.8,
            "count": 0
           },
           {
            "bin_start": 532.8,
            "bin_end": 538.4,
            "count": 0
           },
           {
            "bin_start": 538.4,
            "bin_end": 544,
            "count": 0
           },
           {
            "bin_start": 544,
            "bin_end": 549.6,
            "count": 1
           },
           {
            "bin_start": 549.6,
            "bin_end": 555.2,
            "count": 0
           },
           {
            "bin_start": 555.2,
            "bin_end": 560.8,
            "count": 0
           },
           {
            "bin_start": 560.8,
            "bin_end": 566.4,
            "count": 1
           },
           {
            "bin_start": 566.4,
            "bin_end": 572,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "7 days Moving Average",
         "dtype": "float64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "95.0",
          "max": "111.0",
          "histogram": [
           {
            "bin_start": 95,
            "bin_end": 96.6,
            "count": 1
           },
           {
            "bin_start": 96.6,
            "bin_end": 98.2,
            "count": 2
           },
           {
            "bin_start": 98.2,
            "bin_end": 99.8,
            "count": 0
           },
           {
            "bin_start": 99.8,
            "bin_end": 101.4,
            "count": 0
           },
           {
            "bin_start": 101.4,
            "bin_end": 103,
            "count": 1
           },
           {
            "bin_start": 103,
            "bin_end": 104.6,
            "count": 0
           },
           {
            "bin_start": 104.6,
            "bin_end": 106.2,
            "count": 0
           },
           {
            "bin_start": 106.2,
            "bin_end": 107.8,
            "count": 0
           },
           {
            "bin_start": 107.8,
            "bin_end": 109.4,
            "count": 0
           },
           {
            "bin_start": 109.4,
            "bin_end": 111,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "Percentage Vaccinated",
         "dtype": "float64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "0.7585617305663032",
          "max": "0.7640138937741822",
          "histogram": [
           {
            "bin_start": 0.7585617305663032,
            "bin_end": 0.759106946887091,
            "count": 1
           },
           {
            "bin_start": 0.759106946887091,
            "bin_end": 0.759652163207879,
            "count": 0
           },
           {
            "bin_start": 0.759652163207879,
            "bin_end": 0.7601973795286668,
            "count": 1
           },
           {
            "bin_start": 0.7601973795286668,
            "bin_end": 0.7607425958494548,
            "count": 0
           },
           {
            "bin_start": 0.7607425958494548,
            "bin_end": 0.7612878121702427,
            "count": 0
           },
           {
            "bin_start": 0.7612878121702427,
            "bin_end": 0.7618330284910305,
            "count": 1
           },
           {
            "bin_start": 0.7618330284910305,
            "bin_end": 0.7623782448118185,
            "count": 0
           },
           {
            "bin_start": 0.7623782448118185,
            "bin_end": 0.7629234611326063,
            "count": 1
           },
           {
            "bin_start": 0.7629234611326063,
            "bin_end": 0.7634686774533943,
            "count": 0
           },
           {
            "bin_start": 0.7634686774533943,
            "bin_end": 0.7640138937741822,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "STI Price",
         "dtype": "float64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "3149.25",
          "max": "3186.65",
          "histogram": [
           {
            "bin_start": 3149.25,
            "bin_end": 3152.99,
            "count": 1
           },
           {
            "bin_start": 3152.99,
            "bin_end": 3156.73,
            "count": 1
           },
           {
            "bin_start": 3156.73,
            "bin_end": 3160.4700000000003,
            "count": 0
           },
           {
            "bin_start": 3160.4700000000003,
            "bin_end": 3164.21,
            "count": 0
           },
           {
            "bin_start": 3164.21,
            "bin_end": 3167.95,
            "count": 0
           },
           {
            "bin_start": 3167.95,
            "bin_end": 3171.69,
            "count": 0
           },
           {
            "bin_start": 3171.69,
            "bin_end": 3175.4300000000003,
            "count": 1
           },
           {
            "bin_start": 3175.4300000000003,
            "bin_end": 3179.17,
            "count": 1
           },
           {
            "bin_start": 3179.17,
            "bin_end": 3182.91,
            "count": 0
           },
           {
            "bin_start": 3182.91,
            "bin_end": 3186.65,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "Phase_Phase 2 (Heightened Alert)",
         "dtype": "int64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "1",
          "max": "1",
          "histogram": [
           {
            "bin_start": 0.5,
            "bin_end": 0.6,
            "count": 0
           },
           {
            "bin_start": 0.6,
            "bin_end": 0.7,
            "count": 0
           },
           {
            "bin_start": 0.7,
            "bin_end": 0.8,
            "count": 0
           },
           {
            "bin_start": 0.8,
            "bin_end": 0.9,
            "count": 0
           },
           {
            "bin_start": 0.9,
            "bin_end": 1,
            "count": 0
           },
           {
            "bin_start": 1,
            "bin_end": 1.1,
            "count": 5
           },
           {
            "bin_start": 1.1,
            "bin_end": 1.2000000000000002,
            "count": 0
           },
           {
            "bin_start": 1.2000000000000002,
            "bin_end": 1.3,
            "count": 0
           },
           {
            "bin_start": 1.3,
            "bin_end": 1.4,
            "count": 0
           },
           {
            "bin_start": 1.4,
            "bin_end": 1.5,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "Phase_Preparatory Stage",
         "dtype": "int64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0",
          "max": "0",
          "histogram": [
           {
            "bin_start": -0.5,
            "bin_end": -0.4,
            "count": 0
           },
           {
            "bin_start": -0.4,
            "bin_end": -0.3,
            "count": 0
           },
           {
            "bin_start": -0.3,
            "bin_end": -0.19999999999999996,
            "count": 0
           },
           {
            "bin_start": -0.19999999999999996,
            "bin_end": -0.09999999999999998,
            "count": 0
           },
           {
            "bin_start": -0.09999999999999998,
            "bin_end": 0,
            "count": 0
           },
           {
            "bin_start": 0,
            "bin_end": 0.10000000000000009,
            "count": 5
           },
           {
            "bin_start": 0.10000000000000009,
            "bin_end": 0.20000000000000007,
            "count": 0
           },
           {
            "bin_start": 0.20000000000000007,
            "bin_end": 0.30000000000000004,
            "count": 0
           },
           {
            "bin_start": 0.30000000000000004,
            "bin_end": 0.4,
            "count": 0
           },
           {
            "bin_start": 0.4,
            "bin_end": 0.5,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "Phase_Stabilisation Phase",
         "dtype": "int64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0",
          "max": "0",
          "histogram": [
           {
            "bin_start": -0.5,
            "bin_end": -0.4,
            "count": 0
           },
           {
            "bin_start": -0.4,
            "bin_end": -0.3,
            "count": 0
           },
           {
            "bin_start": -0.3,
            "bin_end": -0.19999999999999996,
            "count": 0
           },
           {
            "bin_start": -0.19999999999999996,
            "bin_end": -0.09999999999999998,
            "count": 0
           },
           {
            "bin_start": -0.09999999999999998,
            "bin_end": 0,
            "count": 0
           },
           {
            "bin_start": 0,
            "bin_end": 0.10000000000000009,
            "count": 5
           },
           {
            "bin_start": 0.10000000000000009,
            "bin_end": 0.20000000000000007,
            "count": 0
           },
           {
            "bin_start": 0.20000000000000007,
            "bin_end": 0.30000000000000004,
            "count": 0
           },
           {
            "bin_start": 0.30000000000000004,
            "bin_end": 0.4,
            "count": 0
           },
           {
            "bin_start": 0.4,
            "bin_end": 0.5,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "Date": 738004,
         "Still Hospitalised": 572,
         "7 days Moving Average": 111,
         "Percentage Vaccinated": 0.7585617305663032,
         "STI Price": 3176.42,
         "Phase_Phase 2 (Heightened Alert)": 1,
         "Phase_Preparatory Stage": 0,
         "Phase_Stabilisation Phase": 0,
         "_deepnote_index_column": 0
        },
        {
         "Date": 738005,
         "Still Hospitalised": 562,
         "7 days Moving Average": 102,
         "Percentage Vaccinated": 0.7599759057333803,
         "STI Price": 3149.25,
         "Phase_Phase 2 (Heightened Alert)": 1,
         "Phase_Preparatory Stage": 0,
         "Phase_Stabilisation Phase": 0,
         "_deepnote_index_column": 1
        },
        {
         "Date": 738006,
         "Still Hospitalised": 525,
         "7 days Moving Average": 95,
         "Percentage Vaccinated": 0.7615117833274709,
         "STI Price": 3154.6,
         "Phase_Phase 2 (Heightened Alert)": 1,
         "Phase_Preparatory Stage": 0,
         "Phase_Stabilisation Phase": 0,
         "_deepnote_index_column": 2
        },
        {
         "Date": 738007,
         "Still Hospitalised": 547,
         "7 days Moving Average": 98,
         "Percentage Vaccinated": 0.762820436158987,
         "STI Price": 3186.65,
         "Phase_Phase 2 (Heightened Alert)": 1,
         "Phase_Preparatory Stage": 0,
         "Phase_Stabilisation Phase": 0,
         "_deepnote_index_column": 3
        },
        {
         "Date": 738008,
         "Still Hospitalised": 516,
         "7 days Moving Average": 97,
         "Percentage Vaccinated": 0.7640138937741822,
         "STI Price": 3175,
         "Phase_Phase 2 (Heightened Alert)": 1,
         "Phase_Preparatory Stage": 0,
         "Phase_Stabilisation Phase": 0,
         "_deepnote_index_column": 4
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "     Date  Still Hospitalised  7 days Moving Average  Percentage Vaccinated  \\\n0  738004                 572                  111.0               0.758562   \n1  738005                 562                  102.0               0.759976   \n2  738006                 525                   95.0               0.761512   \n3  738007                 547                   98.0               0.762820   \n4  738008                 516                   97.0               0.764014   \n\n   STI Price  Phase_Phase 2 (Heightened Alert)  Phase_Preparatory Stage  \\\n0    3176.42                                 1                        0   \n1    3149.25                                 1                        0   \n2    3154.60                                 1                        0   \n3    3186.65                                 1                        0   \n4    3175.00                                 1                        0   \n\n   Phase_Stabilisation Phase  \n0                          0  \n1                          0  \n2                          0  \n3                          0  \n4                          0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Still Hospitalised</th>\n      <th>7 days Moving Average</th>\n      <th>Percentage Vaccinated</th>\n      <th>STI Price</th>\n      <th>Phase_Phase 2 (Heightened Alert)</th>\n      <th>Phase_Preparatory Stage</th>\n      <th>Phase_Stabilisation Phase</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>738004</td>\n      <td>572</td>\n      <td>111.0</td>\n      <td>0.758562</td>\n      <td>3176.42</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>738005</td>\n      <td>562</td>\n      <td>102.0</td>\n      <td>0.759976</td>\n      <td>3149.25</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>738006</td>\n      <td>525</td>\n      <td>95.0</td>\n      <td>0.761512</td>\n      <td>3154.60</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>738007</td>\n      <td>547</td>\n      <td>98.0</td>\n      <td>0.762820</td>\n      <td>3186.65</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>738008</td>\n      <td>516</td>\n      <td>97.0</td>\n      <td>0.764014</td>\n      <td>3175.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "feature_names = ['Date','Still Hospitalised','7 days Moving Average','Percentage Vaccinated','Phase_Phase 2 (Heightened Alert)','Phase_Preparatory Stage','Phase_Stabilisation Phase']\ntarget_name = [\"STI Price\"]\nX = df.loc[:,feature_names]\ny = df.loc[:,target_name]",
   "metadata": {
    "tags": [],
    "cell_id": "00003-780d250a-2e55-46d9-8155-5e85fa3c0a89",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "af817bf3",
    "execution_start": 1636450696879,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": "# Modeling with Linear Regression",
   "metadata": {
    "cell_id": "00015-65965c76-df18-4b74-a997-229f2bfc6e6a",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b38eb430",
    "execution_start": 1636450808271,
    "execution_millis": 0,
    "cell_id": "00017-5ef45bf7-f53a-4572-9bd6-aac9e6bc95e8",
    "deepnote_cell_type": "code"
   },
   "source": "def CostFunction(x,y,w,b):\n    cost = np.sum((((x.dot(w) + b) - y) ** 2) / (2*len(y)))\n    return cost\n\ndef GradientDescent(x, y, w, b, learning_rate, epochs):\n    cost_list = [0] * epochs\n   \n    for epoch in range(epochs):\n        z = x.dot(w) + b\n        loss = z - y\n        \n        weight_gradient = x.T.dot(loss) / len(y)\n        bias_gradient = np.sum(loss) / len(y)\n        \n        w = w - learning_rate*weight_gradient\n        b = b - learning_rate*bias_gradient\n  \n        cost = CostFunction(x, y, w, b)\n        cost_list[epoch] = cost\n        \n        if (epoch%(epochs/10)==0):\n            print(\"Cost is:\",cost)\n        \n    return w, b, cost_list\n\ndef predict(X, w, b):\n    return X.dot(w) + b\n\ndef r2score(y_pred, y):\n    rss = np.sum((y_pred - y) ** 2)\n    tss = np.sum((y-y.mean()) ** 2)\n    \n    r2 = 1 - (rss / tss)\n    return r2\n\ndef train_test_split(df_feature, df_target, random_state=None, test_size=0.5):\n    np.random.seed(random_state)\n    N = df_feature.shape[0]\n    sample = int(test_size*N)\n    train_idx = np.random.choice(N, sample,replace=False)\n    \n    df_feature_train = df_feature.iloc[train_idx]\n    df_target_train = df_target.iloc[train_idx]\n\n    test_idx = [idx for idx in range(N) if idx not in train_idx]\n    \n    df_feature_test = df_feature.iloc[test_idx]\n    df_target_test = df_target.iloc[test_idx]\n\n    return df_feature_train, df_feature_test, df_target_train, df_target_test",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "413a64be",
    "execution_start": 1636450709979,
    "execution_millis": 0,
    "cell_id": "00018-a9cd5c10-bd2e-4c4e-8839-f7a23594f91e",
    "deepnote_cell_type": "code"
   },
   "source": "def standard_scaling(df):\n    dfout = df.apply(lambda x: (x - np.mean(x)) / np.std(x))\n    return dfout\n\ndef min_max_scaling(df):\n    return df.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n\ndef normalization(df):\n    return df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": "def gradient_descent(X, y, theta, alpha, iterations):\n  \"\"\"\n  Compute cost for linear regression.\n\n  Input Parameters\n  ----------------\n  X : 2D array where each row represent the training example and each column represent the feature ndarray. Dimension(m x n)\n      m= number of training examples\n      n= number of features (including X_0 column of ones)\n  y : 1D array of labels/target value for each traing example. dimension(m x 1)\n  theta : 1D array of fitting parameters or weights. Dimension (1 x n)\n  alpha : Learning rate. Scalar value\n  iterations: No of iterations. Scalar value. \n\n  Output Parameters\n  -----------------\n  theta : Final Value. 1D array of fitting parameters or weights. Dimension (1 x n)\n  cost_history: Conatins value of cost for each iteration. 1D array. Dimansion(m x 1)\n  \"\"\"\n  cost_history = np.zeros(iterations)\n\n  for i in range(iterations):\n    predictions = X.dot(theta)\n    #print('predictions= ', predictions[:5])\n    errors = np.subtract(predictions, y)\n    #print('errors= ', errors[:5])\n    sum_delta = (alpha / m) * X.transpose().dot(errors);\n    #print('sum_delta= ', sum_delta[:5])\n    theta = theta - sum_delta;\n\n    cost_history[i] = compute_cost(X, y, theta)  \n\n  return theta, cost_history",
   "metadata": {
    "tags": [],
    "cell_id": "00009-aeba91bd-b916-4087-909d-887ac74742ae",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "13a66927",
    "execution_start": 1636451947724,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "source": "def compute_cost(X, y, theta):\n  \"\"\"\n  Compute the cost of a particular choice of theta for linear regression.\n\n  Input Parameters\n  ----------------\n  X : 2D array where each row represent the training example and each column represent the feature ndarray. Dimension(m x n)\n      m= number of training examples\n      n= number of features (including X_0 column of ones)\n  y : 1D array of labels/target value for each traing example. dimension(1 x m)\n\n  theta : 1D array of fitting parameters or weights. Dimension (1 x n)\n\n  Output Parameters\n  -----------------\n  J : Scalar value.\n  \"\"\"\n  predictions = X.dot(theta)\n  #print('predictions= ', predictions[:5])\n  errors = np.subtract(predictions, y)\n  #print('errors= ', errors[:5]) \n  sqrErrors = np.square(errors)\n  #print('sqrErrors= ', sqrErrors[:5]) \n  #J = 1 / (2 * m) * np.sum(sqrErrors)\n  # OR\n  # We can merge 'square' and 'sum' into one by taking the transpose of matrix 'errors' and taking dot product with itself\n  # If your confuse about this try to do this with few values for better understanding  \n  J = 1/(2 * m) * errors.T.dot(errors)\n\n  return J",
   "metadata": {
    "tags": [],
    "cell_id": "00010-9e620153-4a18-401e-9568-42a1c437e5ed",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4401ec8c",
    "execution_start": 1636451942491,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "source": "import matplotlib.pyplot as plt\nplt.plot(range(1, iterations +1), cost_history, color ='blue')\nplt.rcParams[\"figure.figsize\"] = (10,6)\nplt.grid()\nplt.xlabel(\"Number of iterations\")\nplt.ylabel(\"cost (J)\")\nplt.title(\"Convergence of gradient descent\")",
   "metadata": {
    "tags": [],
    "cell_id": "00010-3400cf20-13ea-4992-bea0-55861ecb7db2",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7974d7ea",
    "execution_start": 1636451747109,
    "execution_millis": 291,
    "cell_id": "00022-dfe67c9e-509d-467a-a369-52d1dec15a90",
    "deepnote_cell_type": "code"
   },
   "source": "# from sklearn.model_selection import train_test_split\n# # Dividing the data into training and testing data\n# X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.25)\n\n# # We need theta parameter for every input variable. since we have three input variable including X_0 (column of ones)\n# theta = np.zeros(3)\n# iterations = 400;\n# alpha = 0.15;\n\n# # call the gradient descent function to get the finalised weights and bias (model training)\n# w, b, c= GradientDescent(X_train, y_train, np.zeros(X_train.shape[1]), 0, 0.002,100)\n# plt.plot(c)\n\n# y_pred = predict(X_test, w, b)\n\n# r2score(y_pred, y_test)",
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "GradientDescent() takes 5 positional arguments but 6 were given",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d2c8e19de3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# call the gradient descent function to get the finalised weights and bias (model training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mGradientDescent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.002\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: GradientDescent() takes 5 positional arguments but 6 were given"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "source": "np.zeros((X_train.shape[0],1))",
   "metadata": {
    "tags": [],
    "cell_id": "00011-7d5bd9fb-4a18-42fb-a41f-bca1040d6fb0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ca9b18cd",
    "execution_start": 1636451333839,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 33,
     "data": {
      "text/plain": "array([[0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.],\n       [0.]])"
     },
     "metadata": {}
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "source": "## Optimization\n",
   "metadata": {
    "tags": [],
    "cell_id": "00023-c5bb9560-6b64-4599-b0ca-9dc8f6d6db80",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b8bffaec",
    "execution_start": 1635253008688,
    "execution_millis": 65,
    "cell_id": "00024-28006553-016c-4594-9f2d-37ea93f4cf1e",
    "deepnote_cell_type": "code"
   },
   "source": "# Building the optimal model using Backward Elimination\n\nimport statsmodels.api as sm\nX = np.append(arr = np.ones((59, 1)).astype(int), values = X, axis = 1)\n# X = np.append(arr = np.ones((59, 1)).astype('float64'), values = X, axis = 1)\n\nX_Optimal = X[:, [0,1,2,3,4,5]]\nX_Optimal = np.array(X_Optimal, dtype=float)\nregressor_OLS = sm.OLS(endog = Y, exog = X_Optimal).fit()\nregressor_OLS.summary()\n\nX_Optimal = X[:, [0,1,2,4,5]]\nX_Optimal = np.array(X_Optimal, dtype=float)\nregressor_OLS = sm.OLS(endog = Y, exog = X_Optimal).fit()\nregressor_OLS.summary()\n\nX_Optimal = X[:, [0,1,4,5]]\nX_Optimal = np.array(X_Optimal, dtype=float)\nregressor_OLS = sm.OLS(endog = Y, exog = X_Optimal).fit()\nregressor_OLS.summary()\n\nX_Optimal = X[:, [0,1,4]]\nX_Optimal = np.array(X_Optimal, dtype=float)\nregressor_OLS = sm.OLS(endog = Y, exog = X_Optimal).fit()\nregressor_OLS.summary()\n\n# Fitting the Multiple Linear Regression in the Optimal Training set\n\nX_Optimal_Train, X_Optimal_Test = train_test_split(X_Optimal,test_size = 0.2, random_state = 0)\nregressor.fit(X_Optimal_Train, Y_Train)\n\n# Predicting the Optimal Test set results\n\nY_Optimal_Pred = regressor.predict(X_Optimal_Test)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "75ff147e",
    "execution_start": 1635252811725,
    "execution_millis": 17,
    "cell_id": "00025-763d61e5-135c-46c3-931e-002bd4e5125a",
    "deepnote_cell_type": "code"
   },
   "source": "# X = merged_df.iloc[:, :-1].values # selects all the columns excluding STI price",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Evaluating the model\n",
   "metadata": {
    "tags": [],
    "cell_id": "00026-f7ddb1e6-ad34-4093-9443-b8ea10ba38ad",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "68ba4ebc",
    "execution_start": 1635253012794,
    "execution_millis": 55,
    "cell_id": "00027-f8d2c8c9-9b57-4874-9e65-ac0eb19db949",
    "deepnote_cell_type": "code"
   },
   "source": "# optimized with bw elimation\nX_Optimal = X[:, [0,1,2,3,4,5]]\nX_Optimal = np.array(X_Optimal, dtype=float)\nregressor_OLS = sm.OLS(endog = Y, exog = X_Optimal).fit()\nprint(regressor_OLS.summary())",
   "outputs": [
    {
     "name": "stdout",
     "text": "                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.529\nModel:                            OLS   Adj. R-squared:                  0.485\nMethod:                 Least Squares   F-statistic:                     11.93\nDate:                Tue, 26 Oct 2021   Prob (F-statistic):           9.36e-08\nTime:                        12:56:52   Log-Likelihood:                -287.59\nNo. Observations:                  59   AIC:                             587.2\nDf Residuals:                      53   BIC:                             599.7\nDf Model:                           5                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst        2.38e+06   5.89e+05      4.044      0.000     1.2e+06    3.56e+06\nx1             4.4917     26.170      0.172      0.864     -47.999      56.983\nx2           -32.5158     33.501     -0.971      0.336     -99.710      34.678\nx3            -3.2206      0.797     -4.039      0.000      -4.820      -1.621\nx4            -0.0525      0.049     -1.063      0.293      -0.152       0.047\nx5             0.0959      0.018      5.218      0.000       0.059       0.133\n==============================================================================\nOmnibus:                        1.329   Durbin-Watson:                   0.338\nProb(Omnibus):                  0.515   Jarque-Bera (JB):                1.353\nSkew:                           0.326   Prob(JB):                        0.508\nKurtosis:                       2.647   Cond. No.                     9.98e+10\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 9.98e+10. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5db9d94a",
    "execution_start": 1635253036233,
    "execution_millis": 9,
    "cell_id": "00028-706b555e-bb45-465a-8d2d-603a221af63c",
    "deepnote_cell_type": "code"
   },
   "source": "Y_Pred",
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 31,
     "data": {
      "text/plain": "array([3087.27157853, 3063.1365116 , 3089.03177691, 3085.2729684 ,\n       3109.35837855, 3166.32833225, 3066.88064559, 3104.94332752,\n       3076.4737427 , 3086.97484616, 3151.43215778, 3116.52180025])"
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1eb6ad89",
    "execution_start": 1635253041479,
    "execution_millis": 13,
    "cell_id": "00029-84b3542a-b0d8-4c3a-ab8d-37d709f4cf49",
    "deepnote_cell_type": "code"
   },
   "source": "# importing r2_score module\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\n\n\n# predicting the accuracy score\nscore=r2_score(Y_Test,Y_Pred)\nprint(f\"r2 score is {score}\")\nprint(f\"mean_sqrd_error is == {mean_squared_error(Y_Test,Y_Pred)}\")\nprint(f\"root_mean_squared error of is == {np.sqrt(mean_squared_error(Y_Test,Y_Pred))}\")\n\n\n# After Optimization with BE\nprint(\"============================\")\nprint(\"After Optimization with Backwards Elimination\")\n# predicting the accuracy score\nscore=r2_score(Y_Test,Y_Optimal_Pred)\nprint(f\"r2 score is {score}\")\nprint(f\"mean_sqrd_error is == {mean_squared_error(Y_Test,Y_Pred)}\")\nprint(f\"root_mean_squared error of is == {np.sqrt(mean_squared_error(Y_Test,Y_Pred))}\")",
   "outputs": [
    {
     "name": "stdout",
     "text": "r2 score is 0.7798496442687198\nmean_sqrd_error is == 375.25938334777646\nroot_mean_squared error of is == 19.371612822575628\n============================\nAfter Optimization with Backwards Elimination\nr2 score is 3.958279437643597e-05\nmean_sqrd_error is == 375.25938334777646\nroot_mean_squared error of is == 19.371612822575628\n",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Data Visualization",
   "metadata": {
    "tags": [],
    "cell_id": "00030-95186cc2-6b43-49df-9636-f364cfa05c6e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "a6eb6ee4",
    "execution_start": 1635224838244,
    "execution_millis": 20,
    "cell_id": "00031-d6da145f-a59a-401d-8170-5e372fa8c115",
    "deepnote_cell_type": "code"
   },
   "source": "import numpy as np\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nx_range = np.linspace(X.min(), X.max(), 100)\ny_range = regressor.predict(x_range.reshape(-1, 1))\n\nfig = px.scatter(df, x='total_bill', y='STI index', opacity=0.65)\nfig.add_traces(go.Scatter(x=x_range, y=y_range, name='Regression Fit'))\nfig.show()",
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "X has 1 features, but LinearRegression is expecting 65 features as input.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5955ed8fb705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'total_bill'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'STI index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopacity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \"\"\"\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             raise ValueError(\n\u001b[0;32m--> 396\u001b[0;31m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features, but LinearRegression is expecting 65 features as input."
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "cell_id": "00032-f54f5d81-9639-4b4d-a67a-6d899493b52d",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=8063f459-52be-4c78-9eaa-2f01d373f9b4' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "44a20da4-484d-459f-ab44-c0848babb7dc",
  "interpreter": {
   "hash": "f8de414fe5ddbccff2f91c39ac2a6f46599db36c34b0eade305cc19fe9870220"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('fastai': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 }
}